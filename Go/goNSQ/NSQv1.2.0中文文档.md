<p style='text-align:center;font-size:30px;font-weight:bold'>NSQ v1.2.0中文文档</p>

# 概览

## 快速开始

下述步骤将在你的本地机器上运行一个小型**NSQ**集群，贯穿了消息的发布、消费以及归档至磁盘。

1. 首先跟随[安装说明](https://nsq.io/deployment/installing.html)文档进行安装；

2. 在shell中开启`nsqlookupd`:

   ```shell
   $ nsqlookupd
   ```

3. 在另一个shell中开启`nsqd`:

   ```shell
   $ nsqd --lookupd-tcp-address=127.0.0.1:4160
   ```

4. 在另一个shell中开启`nsqadmin`：

   ```shell
   $ nsqadmin --lookupd-http-address=127.0.0.1:4161
   ```

5. 发布一个初始消息（也就是在集群中创建一个主题）

   ```shell
   $ curl -d 'hello world 1' 'http://127.0.0.1:4151/pub?topic=test'
   ```

6. 最后，在另一个shell中开启`nsq_to_file`:

   ```shell
   $ nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161
   ```

7. 发布更多消息到`nsqd`:

   ```shell
   $ curl -d 'hello world 2' 'http://127.0.0.1:4151/pub?topic=test'
   $ curl -d 'hello world 3' 'http://127.0.0.1:4151/pub?topic=test'
   ```

8. 为了验证上述工作是否如预期进行，可以打开浏览器地址http://127.0.0.1:4171/ 通过`nsqadmin`UI界面查看统计信息。当然，你也可以检查写到`/tmp`目录下的日志文件(`test.*.log`)内容。

这里有个比较重要的内容是，客户端并没有明确地指明`test`主题从哪里产生，`nsq_to_file`将从`nsqlookupd`提取这些信息，即使正处于连接中，也不会有消息丢失。

## 特征与保证

`NSQ`是一个实时分布式消息平台。

### 特征

* 支持无SPOF的分布式拓扑
* 水平扩展(无代理，可无缝地向集群中添加更多节点)
* 消息传递低延迟推送（[性能](https://nsq.io/overview/performance.html)）
* 负载均衡以及多种风格消息路由组合
* 擅长流式处理（高吞吐量）和面向作业（低吞吐量）的工作负载
* 主要在内存中（超出某个水平，消息将以透明的方式保存在磁盘上）
* 运行时服务发现，对于消费者查找生产者[(nsqlookupd)](https://github.com/nsqio/nsq/tree/master/nsqlookupd/README.md)
* 传输层安全 （TLS）
* 数据格式不可知
* 依赖少，易于部署，具有合理、清晰有界的默认配置
* 简单 TCP 协议支持任何语言的客户端库
* 用于统计信息、管理操作和生产者（无需发布客户端库）的 HTTP 接口
* 与实时检测的[statsd](https://github.com/etsy/statsd/)集成
* 强大的群集管理接口 （[nsqadmin](https://github.com/nsqio/nsq/tree/master/nsqadmin/README.md))

### 保证

> 这部分建议只看看加粗部分就可以了，其他部分不是啥重点，水平有限翻译过来也很拗口，或者直接去看原文。

与任何分布式系统一样，实现你的目标都需要一个明智的权衡过程。通过透明地权衡这些折衷的现实，我们希望对NSQ在生产中部署时的行为设定如下期望：

* **消息不是持久化的(默认)**
  尽管系统支持通过`--mem-queue-size`设置"释放阀(release valve)",消息将被透明地保存在磁盘上，但NSQ主要还是一个基于内存的消息平台。

  **`--mem-queue-size`可以被设置为0以确保所有到来的消息被持久化到磁盘**。在这种情况下，如果节点发生故障，那么您很容易感知到面临的故障会减少（例如OS或底层IO子系统是否发生故障）

  并**没有内置的复制集。**但是，管理这种权衡的方法有很多种，例如部署拓扑和技术以容错的方式主动持久化主题到磁盘。

* **消息至少传递一次**

  与上述密切相关，假定给定的`nsqd`节点不会失败。

  这意味着，**由于各种原因（客户端超时、断开连接、重排队列等），消息可以多次传递**。而执行幂等操作或删除重复信息是客户端的职责。

* **收到的消息是无序的**

  **不能依赖传递给消费者的消息顺序。**

  与消息传递的字面意义类似，消息是重新排列队列的结果，是内存和磁盘存储的组合。事实上每一个`nsqd`节点之间并不共享任何东西。

  通过在你的消费者中引入一个延迟窗口来接收消息并且在处理这些消息之前（尽管为了保持这些不变的消息，必须丢弃掉位于该窗口之外的消息）进行排序，以此来实宽松的排序(即对于给定的消费者，它的消息是有序的，但是在整个集群中却不能保证)是相对直截了当的。

* **消费者最终可以找到所有主题生产者**

  发现服务[(nsqlookupd)](https://github.com/nsqio/nsq/tree/master/nsqlookupd/README.md)被设计为最终一致。 `nsqlookupd`节点不会共同维护状态或应答查询。

  网络分区不会影响可用性，从这层意义上来说，分区的两侧仍然可以应答查询。部署拓扑对缓解这些类型的问题具有最重要的作用。

## 常见问题

### 部署

- **`nsqd`的推荐拓扑是什么？**

  我们强烈建议**在生成消息的任何服务旁边运行一个`nsqd`**

  `nsqd`是一个相对轻量级的进程，具有有限的内存占用，这使得它非常适合"与别人好好玩耍"（*“playing nice with others”*.）。

  这种模式有助于将消息流构建为消费问题，而不是生产问题。

  另一个好处是，这种模式在给定主机上为主题形成了一个独立的、分片的数据孤岛。

  注意：这不是一个绝对的要求，它只是更为简单（见下面的问题）。

- **为什么生产者不能使用`nsqlookupd`来查找发布到哪儿？**

  因为必须告诉消费者在哪里找到他们需要的主题，NSQ提倡**消费者端发现**模型，以减轻前期配置负担。

  然而，对于服务应发布到哪里，这并没有提供任何解决问题的手段。这是鸡和蛋的问题，主题在发布之前并不存在。

  通过对`nsqd`的共同定位（请参阅上面的问题），你完全回避了此问题（你的服务只是发布到本地`nsqd`）， NSQ 的运行时发现系统自然地进行工作。

- **我只想在单个节点上使用 `nsqd`作为工作队列， 这是一个合适的用例吗？**

  是的， `nsqd`在单节点上也可以运行得很好。

  `nsqlookupd`更有利于在较大的分布式环境中使用。

- **我应该运行多少 `nsqlookupd`?**

  通常只有几个，具体取决于集群大小、`nsqd`节点数和消费者数量以及你所需的容错性。

  对于几百台主机和数千个消费者，部署3个或5个就可以很好地工作。

  `nsqlookupd`节点**不需要**协作应答查询。集群中的元数据最终是*一致的*。

### 发布

- **我需要客户端库来发布消息吗？**

  不！只需使用 HTTP端点来发布（ `/pub`和`/mpub` ）。它很简单，很容易，而且几乎在任何编程环境中都无处不在。

  事实上，绝大多数 NSQ 部署都使用 HTTP 来发布。

- **为什么要强制客户端处理TCP 协议的 `PUB` 和`MPUB`命令的响应？**

  我们认为 NSQ 的默认操作模式应优先考虑安全性，我们希望协议简单且一致。

- **`PUB` 或`MPUB`什么时候可能失败？**

  1. 主题名称的格式不正确（字符/长度限制）。请参阅[主题和频道名称规格](https://nsq.io/clients/tcp_protocol_spec.html#notes)。
  2. 消息太大（此限制作为参数被暴露给`nsqd` ）。
  3. 主题正在被删除。
  4. `nsqd`正在清理退出。
  5. 发布期间与客户端连接相关的任何失败时。

  1和 2 应视为编程错误。3和4是不常见的。5是任何基于 TCP 协议自然有的。

- **如何缓解上述第3个问题？**

  删除主题是一个相对不频繁的操作。如果需要删除主题，请协调时间，删除要经过足够的时间，以便发布所引出的主题创建永远不会执行。

### 设计与理论

- **如何推荐命名主题和通道？**

  主题名称应描述流中的数据。

  通道名称应描述其消费者所执行的工作。

  例如，好的主题名称可以为 `encodes`，`decodes`，`api_requests`，`page_views`；好的通道名称为 `archive`，`analytics_increment`，`spam_analysis`。

- **单个`nsqd`可以支持的主题和通道的数量是否有任何限制？**

  没有施加内置限制。它仅受限于`nsqd`所运行主机的内存和 CPU （每个客户端的 CPU 使用率极大地减少[#236](https://github.com/nsqio/nsq/pull/236)）。

- **如何向群集宣布新主题？**

  第一次`PUB`或者`SUB`一个主题将在`nsqd`上创建主题。主题元数据接下来将传播到配置的`nsqlookupd` 。其他订阅者将定期查询`nsqlookupd` 来发现此主题。

- **NSQ 能做 Rpc 吗？**

  这是可能的，但是在设计NSQ时并未考虑到该用例。

  我们打算发布一些文档，以了解如何构建该内容，但在此期间，如果您有兴趣，请伸出援手。

### pynsq 特定的问题

- **你为什么强迫我使用Tornado？**

  `pynsq`最初打算作为以消费者为导向的库，在 Python 的异步框架（特别是由于 NSQ 面向推送的协议）中使用 NSQ 协议要简单得多。

  Tornado的 API 很简单，性能相当好。

- **Tornado的 IOLoop需要发布吗？**

  不需要，`nsqd`暴露了 HTTP 端点(`/PUB`和`/MPUB`)以非常简单的用于编程语言不可知的发布（agnostic publishing）。

  如果你担心 HTTP 的开销，那没有必要。此外，`/mpub`通过批量发布（原子发布！）来减少 HTTP 的开销。

- **我什么时候要使用`Writer`?**

  当高性能和低开销是一个优先事项。

  `Writer`使用TCP协议`PUB`和`MPUB`命令，与其他HTTP同行相比拥有更小的开销。

- **如果我只想 "fire and forget" （我可以容忍消息丢失！**

  使用 `Writer`并且对发布方法不指定回调。

  注意：这只有利于产生更简单的`pynsq`客户端代码，在幕后仍要处理来自`nsqd`的响应（就是说这样做没有性能什么优势）。

特别感谢Dustin Oprea ([@DustinOprea](https://twitter.com/DustinOprea))启动这个常见问题

## 性能

主仓库有一个脚本(`bench/bench.py`)，它会自动执行一个EC2上的分布式基准测试。它会引导N个节点，一些节点正在运行`nsqd`，一些节点在负载生成PUB和SUB应用，然后解析这些节点的输出以供总体聚合。

### 安装

下面运行的命令反应了6个`c3.2xlarge`的默认参数，最便宜的实例类型支持1gbit的链接。3个节点分别运行了一个`nsqd`实例，其余节点运行着`bench_reader(SUB)`实例和`bench_writer(PUB)`实例，以此生成依赖于基准测试模式的负载。

```shell
$ ./bench/bench.py --access-key=... --secret-key=... --ssh-key-name=...
[I 140917 10:58:10 bench:102] launching 6 instances
[I 140917 10:58:12 bench:111] waiting for instances to launch...
...
[I 140917 10:58:37 bench:130] (1) bootstrapping ec2-54-160-145-64.compute-1.amazonaws.com (i-0a018ce1)
[I 140917 10:59:37 bench:130] (2) bootstrapping ec2-54-90-195-149.compute-1.amazonaws.com (i-0f018ce4)
[I 140917 11:00:00 bench:130] (3) bootstrapping ec2-23-22-236-55.compute-1.amazonaws.com (i-0e018ce5)
[I 140917 11:00:41 bench:130] (4) bootstrapping ec2-23-23-40-113.compute-1.amazonaws.com (i-0d018ce6)
[I 140917 11:01:10 bench:130] (5) bootstrapping ec2-54-226-180-44.compute-1.amazonaws.com (i-0c018ce7)
[I 140917 11:01:43 bench:130] (6) bootstrapping ec2-54-90-83-223.compute-1.amazonaws.com (i-10018cfb)
```

### 生产者吞吐量

此基准测试仅测量了生产者的吞吐量，没有额外的负载。消息的大小是100字节，并且消息分布于3个主题中。

```shell
$ ./bench/bench.py --access-key=... --secret-key=... --ssh-key-name=... --mode=pub --msg-size=100 run
[I 140917 12:39:37 bench:140] launching nsqd on 3 host(s)
[I 140917 12:39:41 bench:163] launching 9 producer(s) on 3 host(s)
...
[I 140917 12:40:20 bench:248] [bench_writer] 10.002s - 197.463mb/s - 2070549.631ops/s - 4.830us/op
```

进入速度(`ingress`)约为`2.07mm` msgs/sec，消耗了总计197mb/s的带宽。

### 生产者和消费者吞吐量

此基准通过为生产者和消费者提供服务，更准确地反映了真实情况。同样，消息大小为 100 字节，消息分布在 3 个主题中，每个主题具有单个*通道*（每个通道 24 个客户端）。

```
$ ./bench/bench.py --access-key=... --secret-key=... --ssh-key-name=... --msg-size=100 run
[I 140917 12:41:11 bench:140] launching nsqd on 3 host(s)
[I 140917 12:41:15 bench:163] launching 9 producer(s) on 3 host(s)
[I 140917 12:41:22 bench:186] launching 9 consumer(s) on 3 host(s)
...
[I 140917 12:41:55 bench:248] [bench_reader] 10.252s - 76.946mb/s - 806838.610ops/s - 12.706us/op
[I 140917 12:41:55 bench:248] [bench_writer] 10.030s - 80.315mb/s - 842149.615ops/s - 11.910us/op
```

在大约`842k `和 `806k` msgs/s 的入口和出口时，消耗了 总计156mb/s 的带宽，我们现在在`nsqd`节点上最大化了 CPU 容量。通过引入消费者，`nsqd`需要维护每个通道的消息传递，因此负载自然会更高。

消费者的数量略低于生产者，因为消费者发送的命令数量是生产者的两倍（必须为每条消息发送一个`FIN`命令），从而影响了吞吐量。

再添加 2 个节点（一个`nsqd`和一个负载生成(load-generating)）达到超过 `1mm` msgs/s:

```shell
$ ./bench/bench.py --access-key=... --secret-key=... --ssh-key-name=... --msg-size=100 run
[I 140917 13:38:28 bench:140] launching nsqd on 4 host(s)
[I 140917 13:38:32 bench:163] launching 16 producer(s) on 4 host(s)
[I 140917 13:38:43 bench:186] launching 16 consumer(s) on 4 host(s)
...
[I 140917 13:39:12 bench:248] [bench_reader] 10.561s - 100.956mb/s - 1058624.012ops/s - 9.976us/op
[I 140917 13:39:12 bench:248] [bench_writer] 10.023s - 105.898mb/s - 1110408.953ops/s - 9.026us/op
```

### 单节点性能

免责声明：请记住**，NSQ**旨在以分布式方式使用。单节点性能虽然很重要，但不是我们所要实现的一切。此外， 基准测试是愚蠢的， 但这里多少做个展示：

- 2012 MacBook Air i7 2ghz

- go1.2

- NSQ v0.2.24

- 200 byte message

**GOMAXPROCS=1（1个发布者、1个消费者）**

```shell
$ ./bench.sh 
results...
PUB: 2014/01/12 22:09:08 duration: 2.311925588s - 82.500mb/s - 432539.873ops/s - 2.312us/op
SUB: 2014/01/12 22:09:19 duration: 6.009749983s - 31.738mb/s - 166396.273ops/s - 6.010us/op
```

**GOMAXPROCS=4（4个发布者，4个消费者)**

```shell
$ ./bench.sh 
results...
PUB: 2014/01/13 16:58:05 duration: 1.411492441s - 135.130mb/s - 708469.965ops/s - 1.411us/op
SUB: 2014/01/13 16:58:16 duration: 5.251380583s - 36.321mb/s - 190426.114ops/s - 5.251us/op
```

## 设计

注：有关随附的视觉插图，请参阅此[幻灯片组](https://speakerdeck.com/snakes/nsq-nyc-golang-meetup)。

> 不翻墙你是打不开的。

**NSQ**是[simplequeue](https://github.com/bitly/simplehttp/tree/master/simplequeue) ([simplehttp](https://github.com/bitly/simplehttp)的一部分)的后继者，因此设计为（没有特定顺序）：

- 支持高可用且消除了 SPOFs 的拓扑
- 满足了更强有力的保证消息传递的需要
- 限制了单个进程的内存占用（通过将某些消息持久化到磁盘）
- 极大地简化了生产者和消费者的配置要求
- 提供了简单直接的升级路径
- 提高了效率

### 简化配置和管理

单个`nsqd`实例设计为一次处理多个数据流。数据流称为"主题"，主题有 1 个或多个"通道"（channels）。每个通道接收主题的所有消息副本。实际上，一个通道对应着一个下游消费主题的服务。

主题和通道并未优先配置。通过发布到命名主题或订阅有关命名主题的通道，主题在首次使用时创建。而通过订阅命名通道，通道在首次使用时创建。

主题和通道所有缓冲区数据彼此独立，以防止缓慢的消费导致其他通道的积压（这同样适用于主题级别）。

一个通道通常可以连接多个客户端。假设所有连接的客户端处于准备接收消息的状态，则每条消息都将传递到一个随机的客户端。例如：

![nsqd clients](https://f.cloud.github.com/assets/187441/1700696/f1434dc8-6029-11e3-8a66-18ca4ea10aca.gif)

总之，消息来自主题 -> 通道（每个通道接收该主题的所有消息副本），但从通道 -> 消费者，消息是均匀分布的（每个消费者接收该通道的部分消息）。

**NSQ**还包括一个辅助应用程序`nsqlookupd` ，它提供了一个目录服务，消费者可以在其中查找到提供给他们订阅主题的`nsqd`实例地址。在配置方面，这使消费者与生产者分离（他们只需要知道在哪里联系`nsqlookupd`通用实例，从不是彼此之间直接联系），降低了复杂性和维护成本。

在底层，每个`nsqd`与`nsqlookupd`之间都具有一个 TCP 长连接(long-lived)，并定期推送其状态给`nsqlookupd`。此数据用于`nsqlookupd`将哪些`nsqd`地址通知给消费者。对于消费者，将暴露 HTTP 端点`/lookup`以进行轮询。

要引入新的主题消费者，只需启动一个配置了`nsqlookupd`实例地址的**NSQ**客户端。添加新的消费者或新的发布者无需更改配置，从而大大降低了开销和复杂性。

注意：在将来的版本中，启发式`nsqlookupd` 可能基于深度、连接的客户端数量或其他"智能"策略来返回`nsqd`地址。当前的实现就是全部。归根结底，目标是深度保持在接近于零的水平，确保所有生产者都能够被订阅。

需要注意的重要点是，`nsqd`和 `nsqlookupd`守护进程被设计为独立运行，同类进程之间没有沟通与协作。

我们也认为，通过一种方法来查看、思考和整体管理集群非常重要。我们为了做到这一点而构建了`nsqadmin`。它提供了一个 Web UI 来浏览主题/通道/消费者的层次结构，并检查每个层的深度和其他关键统计信息。此外，它支持一些管理命令，如删除和清空通道（当通道中的消息可以安全地抛出以将深度带回 0 时，这是一个有用的工具）。

![nsqadmin](https://media.tumblr.com/tumblr_mbmsd6YMfS1qj3yp2.png)

### 简单直接的升级路径

这是我们的最高优先事项之一。我们的生产系统处理大量流量，全部基于我们现有的消息传递工具，因此我们需要一种缓慢而有条不紊地升级基础架构特定部分的方法，而影响很小。

首先，在消息*生产者方面，*我们构建的匹配[简单队列](https://github.com/bitly/simplehttp/tree/master/simplequeue)。具体地说，nsqd 会向 POST 二进制数据公开 HTTP 终结点（就像 ）（需要注意的是，终结点需要一个指定"主题"的附加查询参数）。想要切换到开始发布的服务只需进行次要的代码更改。`nsqd``/pub``simplequeue``nsqd`

其次，我们在 Python 和 Go 中构建了与现有库中习惯的功能和习惯性相匹配的库。这通过将代码更改限制在*引导*端，从而缓解了消息使用者端的过渡。所有业务逻辑保持不变。

最后，我们构建了将新旧组件粘合在一起的实用程序。这些都可在存储库中的目录中使用：`examples`

- `nsq_to_file`- 持久地将给定主题的所有消息写入文件
- `nsq_to_http`- 对主题中的所有消息（多个）终结点执行 HTTP 请求

### 消除 SPOF[锚点链接：消除 spof](https://nsq.io/overview/design.html#eliminating-spofs)

**NSQ**设计为以分布式方式使用。 客户端（通过 TCP）连接到**提供**指定主题的所有实例。没有中间人，没有消息经纪人，也没有SPOF：`nsqd`

![nsq clients](https://media.tumblr.com/tumblr_mat85kr5td1qj3yp2.png)

此拓扑消除了对单个、聚合的源进行链链的需要。相反，您直接从**所有生产者**消费。*从技术上讲*，哪个客户端连接到哪个**NSQ**并不重要，只要有足够的客户端连接到所有生产者来满足消息量，您就保证最终将处理所有客户端。

对于 ，通过运行多个实例实现高可用性。它们不直接相互通信，并且数据最终被认为是一致的。使用者*轮*询其配置的所有实例并联合响应。陈旧、无法访问或其他故障节点不会使系统停止运行。`nsqlookupd``nsqlookupd`

### 消息传递保证[锚点链接：邮件传递保证](https://nsq.io/overview/design.html#message-delivery-guarantees)

**NSQ**保证消息将至少**传递一次，**但重复的消息是可能的。消费者应该期待这一点，并去欺骗[或执行幂等](https://en.wikipedia.org/wiki/Idempotence)操作。

此保证作为协议的一部分强制执行，其工作方式如下（假设客户端已成功连接并订阅了主题）：

1. 客户端表示他们已准备好接收消息
2. **NSQ**发送消息并临时将数据存储在本地（在重新排队或超时时）
3. 客户端答复 FIN（完成）或 REQ（重新排队），分别指示成功或失败。如果客户端不回复**NSQ**将在可配置持续时间后超时，并自动重新排队消息）

这可确保导致消息丢失的唯一边缘情况是进程不干净关闭。在这种情况下，内存中的任何消息（或任何未刷新到磁盘的缓冲写入）都会丢失。`nsqd`

如果防止消息丢失至关重要，则即使此边缘情况也可以减轻。一种解决方案是支持接收相同部分消息副本的冗余对（在单独的主机上）。由于您已将使用者写入为幂等，因此在这些消息上重复执行两次操作不会产生下游影响，并允许系统承受任何单节点故障而不丢失消息。`nsqd`

要点是**NSQ**提供了构建基块，以支持各种生产用例和可配置的耐久度。

### 边界内存占用[用于：边界内存占用的锚点链接](https://nsq.io/overview/design.html#bounded-memory-footprint)

```
nsqd`提供了一个配置选项，用于确定给定队列*内存中*保留的消息数。如果队列的深度超过此阈值，则消息将透明地写入磁盘。这会将给定进程的内存占用量限制为：`--mem-queue-size``nsqd``mem-queue-size * #_of_channels_and_topics
```

![message overflow](https://media.tumblr.com/tumblr_mavte17V3t1qj3yp2.png)

此外，精明的观察者可能已经发现，这是一个方便的方式，通过设置此值到低的东西（如 1，甚至 0），以获得更高的交付保证。磁盘支持的队列旨在生存不干净的重新启动（尽管消息可能传递两次）。

此外，与消息传递保证*、干净关闭*（通过发送进程 TERM 信号）相关的安全保留当前在内存中、正在运行、延迟和各种内部缓冲区中的消息。`nsqd`

请注意，名称在字符串中结尾的主题/通道不会缓冲到磁盘，而是在传递 后删除消息。这使不需要消息保证的使用者能够订阅频道。这些短暂的通道也将消失后，其最后一个客户端断开连接。对于临时主题，这意味着至少一个通道已创建、使用和删除（通常是临时通道）。`#ephemeral``mem-queue-size`

### 效率[锚点链接：效率](https://nsq.io/overview/design.html#efficiency)

**NSQ**设计为通过具有简单大小前缀响应的"像 memcached 一样"命令协议进行通信。所有消息数据都保存在核心中，包括尝试次数、时间戳等元数据。这消除了从服务器来回复制数据到客户端，这是重新排队消息时上一个工具链的固有属性。这也简化了客户端，因为它们不再需要负责维护消息状态。

此外，通过降低配置复杂性，设置和开发时间会大大缩短（尤其是在主题使用 >1 的情况下）。

对于数据协议，我们做出了一个关键的设计决策，通过将数据推送到客户端而不是等待它提取来最大化性能和吞吐量。这个概念，我们称之为状态，本质上是客户端流控制的一种形式。`RDY`

当客户端连接到并订阅通道时，它被放置在 0 的状态。这意味着不会向客户端发送任何消息。当客户端准备好接收消息时，它会发送一个命令，将状态更新到某些 # 它准备处理，例如 100。在没有任何附加命令的情况下，100 条消息将推送到客户端（每次为该客户端提供服务器端 RDY 计数）。`nsqd``RDY``RDY`

客户端库旨在发送命令，在计数达到可配置设置的 +25% 时进行更新（并适当考虑与多个实例的连接，适当划分）。`RDY``max-in-flight``nsqd`

![nsq protocol](https://media.tumblr.com/tumblr_mataigNDn61qj3yp2.png)

这是一个显著的性能旋钮，因为一些下游系统能够更容易地批处理消息，并受益于更高的。`max-in-flight`

值得注意的是，由于它*既缓冲又*基于推送，能够满足对流（通道）独立副本的需求，因此我们生成了一个类似于 和组合的*守护程序*。这在简化我们系统的拓扑方面非常强大，我们传统上会维护上面讨论过的较旧的工具链。`simplequeue``pubsub`

### 去[锚点链接： 去](https://nsq.io/overview/design.html#go)

我们很早就做出了一个战略决策，在**Go 中构建 NSQ** [核心](https://golang.org/)。我们最近写了关于我们使用[Go 的博客，](https://word.bitly.com/post/29550171827/go-go-gadget)并提到这个项目 - 浏览该帖子，了解我们对语言的思考可能会有所帮助。

关于**NSQ**，Go 通道（不要与**NSQ**通道混淆）和语言内置的并发功能非常适合 内部工作。我们利用缓冲通道来管理内存中的消息队列，并无缝地将溢出写入磁盘。`nsqd`

通过标准库，可以轻松地编写网络层和客户端代码。内置内存和 cpu 分析挂钩突出显示了优化机会，并且集成需要很少的精力。我们还发现，在隔离中测试组件、使用接口模拟类型以及迭代构建功能非常容易。

## 内部

# 组件

## nsqd

## nsqlookupd

## nsqadmin

## utilities

# 客户端

## 客户端库

## 构建客户端库

## TCP协议规格

# 部署

## 安装

## 生产配置

## 拓扑模式

## docker

# 链接

## Talks and Slides

## Release Notes

## Github Repo

## Issues

## Google Group